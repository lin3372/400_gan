{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "0301_gan_autoencoder_train (iL).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lin3372/400_gan/blob/main/books/generative_deep_learning/0301_gan_autoencoder_train_(iL).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzG1Ho5XFbWt"
      },
      "source": [
        "#Setup "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_COLAB=0\n",
        "USE_GPU=0"
      ],
      "metadata": {
        "id": "PfYT72YVy2zj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gpu"
      ],
      "metadata": {
        "id": "Uo3GgrkryMl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  !nvidia-smi\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "else:\n",
        "  USE_GPU=1\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "kbhZYipNyOKc",
        "outputId": "cf398dd1-13e4-4dae-d1f9-bc332f9edb80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-5a0c26aa01fb>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    get_ipython().magic('tensorflow_version 2.x')\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzDwAuXO7bjO"
      },
      "source": [
        "## mount google drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWSJpsyKqHjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6831a203-dd3c-4ff8-aa6f-b84078ca42d1"
      },
      "source": [
        "import os, sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  print(\"Running in Google Colab, mounting GDrive\")\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  GOOGLE_COLAB=1\n",
        "\n",
        "  PROJ_DATA_DIR = \"/gdrive/MyDrive/github/400_gan/books/generative_deep_learning/log/data_0301/\"\n",
        "  os.makedirs(PROJ_DATA_DIR, exist_ok=True)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab, mounting GDrive\n",
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bPJKW0av13CA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## working directory setting"
      ],
      "metadata": {
        "id": "dtZ-y2Xbymv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. With Colab this prog will clone from davidADSP/GDL_code.git\n",
        "2. With local machine this prog will be running in the directory and the cloned repo will be in \"./src/\"\n",
        "\n",
        " directory\n",
        "* The **data** folder is where to download relevant data sources (chapter 3 onwards)\n",
        "* The **run** folder stores output from the generative models (chapter 3 onwards) \n",
        "* The **utils** folder stores useful functions that are sourced by the main notebooks"
      ],
      "metadata": {
        "id": "hUUkUXU51Z2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (GOOGLE_COLAB==1):\n",
        "  PROJ_WORKING_DIR = \"/gdrive/MyDrive/github/400_gan/books/generative_deep_learning/\"\n",
        "  PROJ_DAT_PATH=PROJ_WORKING_DIR\n",
        "  PROJ_LOG_PATH=PROJ_DAT_PATH + \"log/data_0301/\"\n",
        "else:\n",
        "  PROJ_WORKING_DIR = \"./\"\n",
        "  PROJ_DAT_PATH=PROJ_WORKING_DIR + \"src/\"\n",
        "  PROJ_LOG_PATH=PROJ_DAT_PATH + \"log/data_0301/\"\n",
        "\n",
        "os.makedirs(PROJ_WORKING_DIR, exist_ok=True)  \n",
        "os.makedirs(PROJ_DAT_PATH, exist_ok=True)\n",
        "os.makedirs(PROJ_LOG_PATH, exist_ok=True) "
      ],
      "metadata": {
        "id": "aIueOa5BzqO8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0xneJCDUqtn"
      },
      "source": [
        "## Clone/copy from Github/GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWfBQNfiu_5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5f25d5-3a40-49e8-9ab5-d80db0cf570b"
      },
      "source": [
        "import os\n",
        "import shutil \n",
        "import sys \n",
        "\n",
        "if (GOOGLE_COLAB==1):\n",
        "  try:\n",
        "    !git clone https://github.com/davidADSP/GDL_code.git\n",
        "  except:\n",
        "    print(\"davidADSP/GDL_code clone failed!\")      \n",
        "  else:\n",
        "    print(\"davidADSP/GDL_code cloned!\")\n",
        "    \n",
        "  PROJ_DAT_PATH=\"./GDL_code/\"\n",
        "else: # running on PC\n",
        "  PROJ_DAT_PATH=\"./src/\"\n",
        "\n",
        "sys.path.insert(0, PROJ_DAT_PATH)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'GDL_code' already exists and is not an empty directory.\n",
            "davidADSP/GDL_code cloned!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lis6M8WKNoLT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "96d7b77e-b716-4249-d1cc-510c66ac327a"
      },
      "source": [
        "'''\n",
        "!git config --global user.email \"lin3372@gmail.com\"\n",
        "!git config --global user.name  \"lin3372@gmail.com\"\n",
        "!git clone https://github.com/lin3372/Book_DL_Generative_Learning.git\n",
        "!ls -l\n",
        "%cd Book_DL_Generative_Learning/\n",
        "!ls -l\n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!git config --global user.email \"lin3372@gmail.com\"\\n!git config --global user.name  \"lin3372@gmail.com\"\\n!git clone https://github.com/lin3372/Book_DL_Generative_Learning.git\\n!ls -l\\n%cd Book_DL_Generative_Learning/\\n!ls -l\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB2Ls2eo6RyF"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCNt3SkG6RyG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "096203ef-5466-4af6-955c-0ae4a098b68b"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from utils.loaders import load_mnist\n",
        "from models.AE import Autoencoder"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2dc616d6b51e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAE\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GDL_code/utils/loaders.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvgg19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGFLNNso6RyJ"
      },
      "source": [
        "## Set parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jXCbCqt6RyK"
      },
      "source": [
        "# run params\n",
        "SECTION = 'vae'\n",
        "RUN_ID = '0001'\n",
        "DATA_NAME = 'digits'\n",
        "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
        "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
        "\n",
        "if not os.path.exists(RUN_FOLDER):\n",
        "    os.mkdir(RUN_FOLDER)\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
        "\n",
        "MODE =  'build' #'load' #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6nNOdlTKdxV"
      },
      "source": [
        "'''\n",
        "!ls -1 ./run/${RUN_FOLDER}\n",
        "!ls -1R ./run/${RUN_FOLDER} | wc -l\n",
        "\n",
        "!git config --global user.email \"lin3372@gmail.com\"\n",
        "!git config --global user.name \"lin3372\"\n",
        "!git remote add origin https://lin3372:\"ivan@github33\"@github.com/lin3372/Book_DL_Generative_Learning.git\n",
        "!git add -A\n",
        "!git commit -m ./run/${RUN_FOLDER}\n",
        "!git push -u origin master\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ9dVjld6RyN"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9rAPbvv6RyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ff3f6b-6cc7-4d3f-f303-ee9d638c955f"
      },
      "source": [
        "#(x_train, y_train), (x_test, y_test) = load_mnist()\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pGIFmmh6RyR"
      },
      "source": [
        "## Define the structure of the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Fat-Uy6RyR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "03fcdfd7-040b-4f4e-db8e-4d8527e10c35"
      },
      "source": [
        "AE = Autoencoder(\n",
        "    input_dim = (28,28,1)\n",
        "    , encoder_conv_filters = [32,64,64, 64]\n",
        "    , encoder_conv_kernel_size = [3,3,3,3]\n",
        "    , encoder_conv_strides = [1,2,2,1]\n",
        "    , decoder_conv_t_filters = [64,64,32,1]\n",
        "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
        "    , decoder_conv_t_strides = [1,2,2,1]\n",
        "    , z_dim = 2\n",
        ")\n",
        "\n",
        "if MODE == 'build':\n",
        "    AE.save(RUN_FOLDER)\n",
        "else:\n",
        "    AE.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2cbc3320019b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m AE = Autoencoder(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mencoder_conv_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mencoder_conv_kernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mencoder_conv_strides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Autoencoder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_hJ1alc6RyV"
      },
      "source": [
        "AE.encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuTB6UDP6RyX"
      },
      "source": [
        "AE.decoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UXIoepG6Rya"
      },
      "source": [
        "## Train the autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-Le7P0s6Ryb"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "BATCH_SIZE = 32\n",
        "INITIAL_EPOCH = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6aQpFTC6Rye"
      },
      "source": [
        "AE.compile(LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hk3HsZ56Ryg"
      },
      "source": [
        "AE.train(     \n",
        "    x_train[:1000]\n",
        "    , batch_size = BATCH_SIZE\n",
        "    , epochs = 200\n",
        "    , run_folder = RUN_FOLDER\n",
        "    , initial_epoch = INITIAL_EPOCH\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzNyo_Gf6Ryj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}